{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "2f1eed92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "\n",
    "\n",
    "import time\n",
    "import copy\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "1fb8e211",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "16ffae3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    args['device'] = torch.device('cuda')\n",
    "else:\n",
    "    args['device'] = torch.device('cpu')\n",
    "    \n",
    "print(args['device'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c574bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = \"..\\Keras\\cats_and_dogs\"\n",
    "train_dir = os.path.join(base_dir, \"train\")\n",
    "validation_dir = os.path.join(base_dir, \"validation\")\n",
    "\n",
    "tr_dir_cats = os.path.join(train_dir, \"cats\")\n",
    "tr_dir_dogs = os.path.join(train_dir, \"dogs\")\n",
    "val_dir_cats = os.path.join(validation_dir, \"cats\")\n",
    "val_dir_dogs = os.path.join(validation_dir, \"dogs\")\n",
    "\n",
    "num_tr_cats = len(os.listdir(tr_dir_cats))\n",
    "num_tr_dogs = len(os.listdir(tr_dir_dogs))\n",
    "num_val_cats = len(os.listdir(val_dir_cats))\n",
    "num_val_dogs = len(os.listdir(val_dir_dogs))\n",
    "\n",
    "num_tr = num_tr_cats + num_tr_dogs\n",
    "num_val = num_val_cats + num_val_dogs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "8ab1b3a9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12499, 12498, 500, 500)"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_tr_cats, num_tr_dogs, num_val_cats, num_val_dogs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "b044560f",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize(255),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5], [0.5])\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "0ecf256b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = datasets.ImageFolder(train_dir, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "1162bbb7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['cats', 'dogs'], 24997)"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_train.classes, len(dataset_train.imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "a2f6a82c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_val = datasets.ImageFolder(validation_dir, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "739cfbb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['cats', 'dogs'], 1000)"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_val.classes, len(dataset_val.imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "07f6d035",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "216dbde2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = DataLoader(dataset=dataset_train, shuffle=True, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "8012abc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_set = DataLoader(dataset=dataset_val, shuffle=False, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "ffc8c675",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model(\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      "  (conv1): Conv2d(3, 6, kernel_size=(4, 4), stride=(1, 1))\n",
      "  (conv2): Conv2d(6, 12, kernel_size=(4, 4), stride=(1, 1))\n",
      "  (conv3): Conv2d(12, 14, kernel_size=(4, 4), stride=(1, 1))\n",
      "  (conv4): Conv2d(14, 16, kernel_size=(4, 4), stride=(1, 1))\n",
      "  (conv5): Conv2d(16, 20, kernel_size=(4, 4), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=320, out_features=250, bias=True)\n",
      "  (fc2): Linear(in_features=250, out_features=200, bias=True)\n",
      "  (fc3): Linear(in_features=200, out_features=50, bias=True)\n",
      "  (fc4): Linear(in_features=50, out_features=10, bias=True)\n",
      "  (fc5): Linear(in_features=10, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class Model(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        \n",
    "        self.pool = nn.MaxPool2d(2,2)\n",
    "        self.dropout = nn.Dropout(p=0.2)\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=6, kernel_size=4)\n",
    "        self.conv2 = nn.Conv2d(in_channels=6, out_channels=12, kernel_size=4)\n",
    "        self.conv3 = nn.Conv2d(in_channels=12, out_channels=14, kernel_size=4)\n",
    "        self.conv4 = nn.Conv2d(in_channels=14, out_channels=16, kernel_size=4)\n",
    "        self.conv5 = nn.Conv2d(in_channels=16, out_channels=20, kernel_size=4)\n",
    "        \n",
    "        self.fc1 = nn.Linear(in_features=20*4*4, out_features=250)\n",
    "        self.fc2= nn.Linear(in_features=250, out_features=200)\n",
    "        self.fc3= nn.Linear(in_features=200, out_features=50)\n",
    "        self.fc4= nn.Linear(in_features=50, out_features=10)\n",
    "        self.fc5= nn.Linear(in_features=10, out_features=2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = self.pool(F.relu(self.conv3(x)))\n",
    "        x = self.pool(F.relu(self.conv4(x)))\n",
    "        x = self.pool(F.relu(self.conv5(x)))\n",
    "        \n",
    "        x = x.reshape(-1, 20 * 4 * 4)\n",
    "        x = self.dropout(F.relu(self.fc1(x)))\n",
    "        x = self.dropout(F.relu(self.fc2(x)))\n",
    "        x = self.dropout(F.relu(self.fc3(x)))\n",
    "        x = self.dropout(F.relu(self.fc4(x)))\n",
    "        x = self.fc5(x)\n",
    "        return x\n",
    "    \n",
    "net = Model().to(args['device'])\n",
    "\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "fa8b7301",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001, weight_decay = 1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "f1cdff25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "oi\n",
      "oi\n",
      "oi\n",
      "oi\n",
      "oi\n",
      "oi\n",
      "oi\n",
      "oi\n",
      "oi\n",
      "oi\n",
      "oi\n",
      "oi\n",
      "oi\n",
      "oi\n",
      "oi\n",
      "oi\n",
      "oi\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-173-0c3c8e9a62c0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[0mrunning_loss\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    253\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    254\u001b[0m                 inputs=inputs)\n\u001b[1;32m--> 255\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    256\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    257\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    145\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    146\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 147\u001b[1;33m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[0;32m    148\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "net.train()\n",
    "\n",
    "for epoch in range(1):\n",
    "    total_correct = 0.0\n",
    "    running_loss = 0.0\n",
    "    for i, (inputs, labels) in enumerate(train_set):\n",
    "        inputs, labels = inputs.to(args['device']), labels.to(args['device'])\n",
    "        output = net(inputs)\n",
    "        output_idx = torch.argmax(output, dim=1)\n",
    "        total_correct += (labels == output_idx).sum().item()\n",
    "        optimizer.zero_grad()\n",
    "        loss = criterion(output, labels)\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    print(f'Epoch: {epoch} Loss: {running_loss/num_tr} Accuracy:{(total_correct/num_tr)*100}%')\n",
    "    \n",
    "print('Finished training')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
